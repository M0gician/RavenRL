import numpy as np
from scipy import stats, optimize


def studentT_interval(std: np.ndarray, d_size: int, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A helper function calculates the concentration interval using student-t distribution.
    Requires a normality assumption, which is mostly likely not met in most MDPs

    Parameters
    ----------
    std : np.ndarray
        The standard deviation over the samples
    d_size : int
        The sample size
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    reference_size = d_size if ref_size is None else ref_size
    interval_correction = 1 if correction is None else correction
    sample_std = std

    if mode == "one":
        t = stats.t.ppf(1 - delta, reference_size - 1)
        interval = t * sample_std / np.sqrt(reference_size)
    elif mode == "two":
        t = stats.t.ppf(1 - delta / 2, reference_size - 1)
        interval = t * sample_std / np.sqrt(reference_size)
    else:
        raise ValueError(f"mode can only be \"one\" or \"two\".")

    return interval_correction * interval


def studentT_lb(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the lower bound using student-t distribution.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    sample_variance = np.sum((X - sample_mean) ** 2) / (data_size - 1)
    sample_std = np.sqrt(sample_variance)
    interval = studentT_interval(
        sample_std, data_size, ref_size, correction, delta, mode)

    return sample_mean - interval


def studentT_ub(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the upper bound using student-t distribution.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    sample_variance = np.sum((X - sample_mean) ** 2) / (data_size - 1)
    sample_std = np.sqrt(sample_variance)
    interval = studentT_interval(
        sample_std, data_size, ref_size, correction, delta, mode)

    return sample_mean + interval


def hoeffding_interval(d_max: float, d_min: float, d_size: int, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A helper function calculates the concentration interval using Hoeffding inequality.
    No assumptions over the sampled distribution.

    Parameters
    ----------
    d_max : float
        The maximum member of the sample data
    d_min : float
        The minimum member of the sample data
    d_size : int
        The sample size
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    b = d_max - d_min
    reference_size = d_size if ref_size is None else ref_size
    interval_correction = 1 if correction is None else correction

    if mode == "one":
        interval = b * np.sqrt(np.log(1 / delta) / (2 * reference_size))
    elif mode == "two":
        interval = b * np.sqrt(np.log(2 / delta) / (2 * reference_size))
    else:
        raise ValueError(f"mode can only be \"one\" or \"two\".")

    return interval_correction * interval


def hoeffding_lb(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the lower bound using Hoeffding inequality.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    interval = hoeffding_interval(X.max(), X.min(), data_size,
        ref_size, correction, delta, mode)

    return sample_mean - interval


def hoeffding_ub(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the upper bound using Hoeffding inequality.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    interval = hoeffding_interval(X.max(), X.min(), data_size,
        ref_size, correction, delta, mode)

    return sample_mean + interval


def MPeB_interval(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A helper function calculates the concentration interval using Maurer-Pontil Empirical Bernstein Bounds.
    No assumptions over the sampled distribution.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    b = X.max() - X.min()
    data_size = X.shape[0]
    reference_size = data_size if ref_size is None else ref_size
    interval_correction = 1 if correction is None else correction

    diff_mat = np.repeat(X.reshape(-1, 1), data_size, axis=1) - X
    diff_mat = diff_mat**2

    if mode == "one":
        interval_1 = (7 * b * np.log(2/delta)) / (3 * reference_size - 3)
        interval_2 = np.sqrt(
            (np.log(2/delta) * np.sum(diff_mat)) / (reference_size-1)
        ) / reference_size
    elif mode == "two":
        interval_1 = (7 * b * np.log(2 / (delta/2))) / (3 * reference_size - 3)
        interval_2 = np.sqrt(
            2.0 * (np.log(2 / delta) * np.sum(diff_mat)) / (reference_size - 1)
        ) / reference_size
    else:
        raise ValueError(f"mode can only be \"one\" or \"two\".")

    return interval_correction * (interval_1 + interval_2)


def MPeB_lb(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the lower bound using Maurer-Pontil Empirical Bernstein Bounds.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    interval = MPeB_interval(X, ref_size, correction, delta, mode)

    return sample_mean - interval


def MPeB_ub(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    """
    A function calculates the upper bound using Maurer-Pontil Empirical Bernstein Bounds.

    Parameters
    ----------
    X : np.ndarray
        The sample data
    ref_size : int
        The size of the safety dataset
    correction : int
        A hyperparameter used to scale the concentration interval generated by `ci_ub`.
        For student t, use `2` in candidate selection; Otherwise use `1`.
    delta : float
        The significance level.
    mode : str
        "one" for one-sided test; "two" for two-sided test
    """
    data_size = X.shape[0]
    sample_mean = np.average(X)
    interval = MPeB_interval(X, ref_size, correction, delta, mode)

    return sample_mean + interval


def c_star(c, D_pre, n_pre, n_post, delta):
    Yi_matrix = c * np.ones((D_pre.shape[0], 2))
    Yi_matrix[:, :-1] = D_pre.reshape(-1, 1)
    Yi_matrix = np.min(Yi_matrix, axis=1)

    term1 = np.sum(Yi_matrix) / n_pre

    term2 = (7 * c * np.log(2 / delta)) / (3 * (n_post - 1))

    term3_1 = np.log(2 / delta) / n_post
    term3_2 = 2 / (n_pre * (n_pre-1))
    term3_3 = n_pre * np.sum(Yi_matrix**2) - np.sum(Yi_matrix)**2
    term3 = np.sqrt(term3_1 * term3_2 * term3_3)

    return -term1 + term2 + term3


def extMPeB_interval(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    b = X.max() - X.min()
    data_size = X.shape[0]
    reference_size = data_size if ref_size is None else ref_size
    interval_correction = 1 if correction is None else correction

    np.random.shuffle(X)
    D_pre = X[:int(data_size / 10)]
    D_post = X[int(data_size / 10):]
    n_pre, n_post = D_pre.shape[0], D_post.shape[0]

    if mode == "one":
        pass
    elif mode == "two":
        delta /= 2
    else:
        raise ValueError(f"mode can only be \"one\" or \"two\".")

    c_i = optimize.minimize_scalar(
        fun=c_star,
        args=(D_pre, n_pre, n_post, delta),
        bounds=(0, 99),
        method="bounded"
    ).x

    Yi_matrix = c_i * np.ones((n_post, 2))
    Yi_matrix[:, :-1] = D_post.reshape(-1, 1)
    Yi_matrix = np.min(Yi_matrix, axis=1) / c_i

    term0 = n_post * (1 / c_i)
    sample_mean = (np.sum(Yi_matrix)) / term0

    term2 = (7 * n_post * np.log(2 / delta)) / (3 * (n_post - 1)) / term0
    term3_1 = np.log(2 / delta) / (n_post - 1)
    term3_2 = np.sum((np.repeat(Yi_matrix.reshape(-1,1), n_post, axis=1) - Yi_matrix)**2)
    term3 = np.sqrt(term3_1 * term3_2) / term0

    return sample_mean, interval_correction * (term2 + term3)


def extMPeB_lb(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    sample_mean, interval = extMPeB_interval(X, ref_size, correction, delta, mode)

    return sample_mean - interval


def extMPeB_ub(X: np.ndarray, ref_size=None, correction=None, delta=0.05, mode="one"):
    sample_mean, interval = extMPeB_interval(X, ref_size, correction, delta, mode)

    return sample_mean + interval


def mcma(X: np.ndarray, delta=0.05, mc_size=10000):
    """
    A function calculates the 1-delta percentile of the sample using Monte-Carlo M_alpha method.
    No assumptions over the sampled distribution.

    For more details, please check the paper:
        "A New Confidence Interval for the Mean of a Bounded Random Variable"
        https://arxiv.org/pdf/1905.06208.pdf

    Parameters
    ----------
    X : np.ndarray
        The sample data
    delta : float
        The significance level.
    mc_size : int
        The sample size for Monte Carlo estimation
    """
    mc_size = int(mc_size)
    n = X.shape[0]
    z = np.sort(X)
    s_prime = np.ones(n)
    s_prime[:-1] = z[1:]
    s = s_prime - z

    u = np.sort(np.random.uniform(0, 1, (mc_size, n)), axis=1)
    ms = 1 - (s.reshape(1, -1) @ u.T)
    ms = np.sort(ms.ravel())

    return ms[int(np.ceil((1-delta) * (mc_size-2))) - 1]


def mcma_lb(X: np.ndarray, ref_size=None, correction=None, mode=None, delta=0.05, mc_size=10000):
    """
    A function calculates the lower bound using Monte-Carlo M_alpha method.

    For more details, please check the paper:
        "A New Confidence Interval for the Mean of a Bounded Random Variable"
        https://arxiv.org/pdf/1905.06208.pdf

    Parameters
    ----------
    X : np.ndarray
        The sample data
    delta : float
        The significance level.
    mc_size : int
        The sample size for Monte Carlo estimation
    """
    return mcma(X, 1-delta, mc_size)


def mcma_ub(X: np.ndarray, ref_size=None, correction=None, mode=None, delta=0.05, mc_size=10000):
    """
    A function calculates the upper bound using Monte-Carlo M_alpha method.

    For more details, please check the paper:
        "A New Confidence Interval for the Mean of a Bounded Random Variable"
        https://arxiv.org/pdf/1905.06208.pdf

    Parameters
    ----------
    X : np.ndarray
        The sample data
    delta : float
        The significance level.
    mc_size : int
        The sample size for Monte Carlo estimation
    """
    return mcma(X, delta, mc_size)


if __name__ == "__main__":
    # pop = np.random.randn(100)
    pop = np.random.geometric(0.35, 100)
    sample = np.random.choice(pop, 20)
    sample_prime = (sample - sample.min()) / (sample.max() - sample.min())
    s_sum = sample_prime.sum()
    s_mean = sample_prime.mean()
    s_squared = 0
    for i in range(sample_prime.size):
        s_squared += sample_prime[i] * sample_prime[i]
    print(f"{s_sum} {s_mean} {s_squared}")
    print(f"mean: {sample.mean()}; size: {sample.size}, b: {sample.max()}, a: {sample.min()}")
    print(f"    MC Ma CI: [{mcma_lb(sample)}, {mcma_ub(sample)}]")
    print(f"Student t CI: [{studentT_lb(sample, correction=2)}, {studentT_ub(sample, correction=2)}]")
    print(f"Hoeffding CI: [{hoeffding_lb(sample, correction=1)}, {hoeffding_ub(sample, correction=1)}]")
    print(f"     MPeB CI: [{MPeB_lb(sample, correction=1)}, {MPeB_ub(sample, correction=1)}]")
    print(f"  extMPeB CI: [{extMPeB_lb(sample, correction=1)}, {extMPeB_ub(sample, correction=1)}]")
